{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "\n",
    "\n",
    "- SBU est 7 jam \n",
    "\n",
    "- RUN ON: tanggal 5 jam 15 -> tanggal 5 jam 8\n",
    "\n",
    "- Corn Config: 0 0 8 5 1/1 ? *\n",
    "\n",
    "\n",
    "\n",
    "## this notebook was part 1/2 of SBU level\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "import sqlalchemy as sql\n",
    "from sqlalchemy.pool import NullPool\n",
    "import gc\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy.sql import text\n",
    "import calendar\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to DWH\n",
    "username = \"\"\n",
    "password = \"********\"\n",
    "host = \"\" \n",
    "\n",
    "\n",
    "connect_string = 'mysql://'+username+':'+quote(password)+'@'+host+'/?charset=utf8mb4'\n",
    "sql_engine_server = sql.create_engine(connect_string, poolclass=NullPool)\n",
    "sql_engine_server.connect()\n",
    "\n",
    "# configure max lenght\n",
    "query = text(\"SET GLOBAL group_concat_max_len = 10000\")\n",
    "sql_engine_server.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test Conection\n",
    "connect_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test concection\n",
    "sql.create_engine(connect_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Declare Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get transaction period for the current update fot the threshold period\n",
    "\n",
    "def monthdelta(date, delta):\n",
    "    m, y = (date.month+delta) % 12, date.year + ((date.month)+delta-1) //12\n",
    "    if not m: m = 12\n",
    "    d = min(date.day, \n",
    "        [31, 29 if y%4==0 and (not y%100==0 or y%400 == 0) else 28,\n",
    "        31,30,31,30,31,31,30,31,30,31][m-1])\n",
    "    return date.replace(day=d,month=m,year=y)\n",
    "    \n",
    "m=monthdelta(datetime.today(), -1).month\n",
    "y=monthdelta(datetime.today(), -1).year\n",
    "d=calendar.monthrange(y, m)[1]\n",
    "prev_year = datetime(y, m, d).year-1\n",
    "end_period = str(datetime(y, m, d).date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate SBU from helper\n",
    "\n",
    "q1=\"\"\"SELECT DISTINCT SBU FROM gclub.rfm_helper\"\"\"\n",
    "df_sbu0 = pd.read_sql_query(q1, sql_engine_server)\n",
    "df_sbu0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional if some SBU want to exclude\n",
    "\n",
    "# df_sbu_0 = df_sbu0.iloc[:5]\n",
    "# df_sbu_1 = df_sbu0.iloc[6:]\n",
    "# df_sbu = pd.concat([df_sbu_0,df_sbu_1])\n",
    "# df_sbu= df_sbu0.iloc[5:6]\n",
    "\n",
    "df_sbu = df_sbu0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappping\n",
    "\n",
    "\n",
    "all_sbu_mapping = []\n",
    "\n",
    "for sbu_list in df_sbu['SBU']:\n",
    "    all_sbu_mapping.append(\n",
    "    {\n",
    "\n",
    "    f'{sbu_list}': \n",
    "    {\n",
    "        \n",
    "    'helper_rfm':\n",
    "    f\"\"\" SELECT\n",
    "        rule.TransactionID,\n",
    "        rule.MemberID,\n",
    "        rule.AtLocationTime,\n",
    "        results.RetailValueAfterTax VALUE,\n",
    "        store.ConceptName\n",
    "    FROM mardiyan.LoyaltyRuleServiceTransactions PARTITION(P2023,P2022,P2021)  rule\n",
    "    INNER JOIN mardiyan.LoyaltyRuleServiceTransactionResults PARTITION(P2023,P2022,P2021)  results\n",
    "        on rule.TransactionID = results.TransactionID\n",
    "    LEFT join\n",
    "    mardiyan.MasterStoresV2 store\n",
    "    ON\n",
    "        rule.LocationReference = store.StoreCode\n",
    "        AND rule.AtLocationTime BETWEEN store.ValidFrom AND store.ValidUntil    \n",
    "    LEFT JOIN gclub.rfm_helper help \n",
    "    ON\n",
    "    store.conceptname = help.`Concept Name`\n",
    "    WHERE\n",
    "        help.SBU =  \"{sbu_list}\"\n",
    "        AND rule.AtLocationTime > Date_sub('<end_period>', INTERVAL 2 year)\n",
    "        AND rule.AtLocationTime <= '<end_period>'\n",
    "        AND rule.Status = 'COMPLETED'\n",
    "        \"\"\",\n",
    "\n",
    "    'rfm_query':\n",
    "    f\"\"\"SELECT\n",
    "    b.MemberID AS member_id,\n",
    "    \"{sbu_list}\" AS SBU,\n",
    "    'dynamic' AS threshold ,\n",
    "    Date_sub('<end_period>', INTERVAL 2 YEAR) AS start_period,\n",
    "    '<end_period>' AS end_period,\n",
    "    COUNT(DISTINCT(b.TransactionID)) freq,\n",
    "    SUM(b.VALUE) total_value,\n",
    "    AVG(b.VALUE) avg_value,\n",
    "    max(DATEDIFF(b.AtLocationTime, '<end_period>')) recency_days\n",
    "    FROM\n",
    "    dev_db.temp_rfm_market b\n",
    "    GROUP BY\n",
    "    b.MemberID\n",
    "    \"\"\",\n",
    "    \n",
    "    'helper_forgot':\n",
    "    f\"\"\"SELECT\n",
    "            DISTINCT a.ssoid\n",
    "        FROM\n",
    "            gclub.MemberIDgroupBySales_2016_2018 a \n",
    "            LEFT JOIN gclub.rfm_helper help \n",
    "            ON\n",
    "            a.ConceptName = help.`Concept Name`\n",
    "        WHERE\n",
    "            help.SBU = \"{sbu_list}\"\n",
    "    UNION ALL\n",
    "        select DISTINCT rule.memberid ssoid  \n",
    "        FROM\n",
    "        mardiyan.LoyaltyRuleServiceTransactions PARTITION(P2023,P2022,P2021,P2020,P2019) rule\n",
    "    LEFT JOIN mardiyan.MasterStoresV2 store ON\n",
    "            rule.LocationReference = store.StoreCode\n",
    "            AND rule.AtLocationTime BETWEEN store.ValidFrom AND store.ValidUntil\n",
    "    LEFT JOIN gclub.rfm_helper help \n",
    "    ON\n",
    "    store.conceptname = help.`Concept Name`\n",
    "    WHERE\n",
    "        help.SBU =\"{sbu_list}\"\n",
    "            AND rule.atlocationtime >= '2019-01-01'\n",
    "            AND rule.atlocationtime <= '<end_period>' \n",
    "            AND rule.Status = 'COMPLETED' \"\"\" ,\n",
    "    \n",
    "    'forgotten_user_query': \n",
    "    f\"\"\"\n",
    "   SELECT\n",
    "    \"{sbu_list}\" SBU,\n",
    "    Date_sub('<end_period>', INTERVAL 2 YEAR) start_period,\n",
    "    '<end_period>' end_period,\n",
    "    (\n",
    "    SELECT\n",
    "        COUNT(DISTINCT dev_db.temp_rfm_market_forgotten_users.ssoid)\n",
    "    FROM\n",
    "         dev_db.temp_rfm_market_forgotten_users ) - <count_current_rfm> forgotten_users\n",
    "         \"\"\"\n",
    "}\n",
    "}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(all_sbu_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_error_concept = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class rfm:\n",
    "    \n",
    "    def __init__(self, df, segment_map, threshold={}, order='rfm'):\n",
    "        self.segment_map=segment_map\n",
    "        self.order=order\n",
    "        self.df = df\n",
    "        self.threshold = threshold.copy()\n",
    "        #if the threshold is not set manually, it will be automatically set using the df distribution (quantile)\n",
    "        \n",
    "        if self.threshold=={}:\n",
    "            self.threshold['recency'] = [self.df.recency_days.quantile(.25),self.df.recency_days.quantile(.5),self.df.recency_days.quantile(.75)]\n",
    "            self.threshold['frequency'] = [self.df.freq.quantile(.25),self.df.freq.quantile(.5),self.df.freq.quantile(.75)]\n",
    "            self.threshold['monetary'] = [self.df.total_value.quantile(.25),self.df.total_value.quantile(.5),self.df.total_value.quantile(.75)]\n",
    "            \n",
    "    #set the threshold manually\n",
    "    def set_threshold(self,threshold={}):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "\n",
    "    def tier_marker(self,series,metric):\n",
    "        q = self.threshold[metric]\n",
    "        return series.apply(lambda x: 4 if x <= q[0] else 3 if (x > q[0] and x <= q[1]) else 2 if (x > q[1] and x <= q[2]) else 1  )\n",
    "        \n",
    "        \n",
    "    def fit(self):\n",
    "        self.df['recency_tier'] = self. tier_marker(self.df.recency_days,'recency')\n",
    "        self.df['freq_tier'] = self.tier_marker(self.df.freq,'frequency')\n",
    "        self.df['total_value_tier'] = self.tier_marker(self.df.total_value,'monetary')\n",
    "        #self.df['avg_value_tier'] = self.tier_marker(self.df.avg_value)\n",
    "\n",
    "        if self.order=='mfr':\n",
    "            self.df['combined_tier'] = self.df.apply(lambda x :   str(x.total_value_tier)+ str(x.freq_tier) + str(x.recency_tier), axis=1 )\n",
    "        elif self.order=='fmr':\n",
    "            self.df['combined_tier'] = self.df.apply(lambda x :   str(x.freq_tier) + str(x.total_value_tier)+str(x.recency_tier), axis=1 )\n",
    "        elif self.order=='frm':\n",
    "            self.df['combined_tier'] = self.df.apply(lambda x :   str(x.freq_tier) +str(x.recency_tier) + str(x.total_value_tier), axis=1 )\n",
    "        else:\n",
    "            #rfm order\n",
    "            self.df['combined_tier'] = self.df.apply(lambda x : str(x.recency_tier) + str(x.freq_tier) + str(x.total_value_tier), axis=1 )\n",
    "        \n",
    "        self.df['segment'] = self.df['combined_tier'].replace(self.segment_map, regex=True)\n",
    "    \n",
    "        rank_map = {\n",
    "                    'Champion':1,\n",
    "                   'Promising':2,\n",
    "                   'Loyalist':3,\n",
    "                   'Potential Loyalist':4,\n",
    "                   'Unsteady':5,\n",
    "                   'Needs Attention':6,\n",
    "                    'At Risk':7,\n",
    "                    'About to Lose':8\n",
    "                   }\n",
    "        self.df['segment_rank'] = self.df['segment'].apply(lambda x: rank_map[x])\n",
    "        return self.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_threshold(sbu,m, year, segment_map, order):\n",
    "    #create 1 year rfm to generate 1-year threshold which will be applied to 2-year rfm\n",
    "    end_date=str(year)+\"-12-31\"\n",
    "    tr=[]\n",
    "    sql_engine = sql_engine_server\n",
    "    # sql_engine = sql.create_engine('mysql://mohammad:%s@147.139.173.222/?charset=utf8'% quote('P@ssw0rd2019!'))\n",
    "    \n",
    "    q=text(m['rfm_query'].replace('<end_period>',str(end_date)).replace('<n_year>',str(1)))\n",
    "    print(q)\n",
    "    df_rfm1 = pd.read_sql(q, sql_engine)\n",
    "    \n",
    "    rfm_base_model = rfm(df_rfm1.copy(),segment_map, order=order)\n",
    "    print(rfm_base_model.threshold)\n",
    "    \n",
    "    \n",
    "    df_tr = pd.DataFrame()\n",
    "    df_tr['threshold'] = [rfm_base_model.threshold,]\n",
    "    df_tr['SBU']= sbu\n",
    "    df_tr['mapping']= q\n",
    "    df_tr['period'] = end_date\n",
    "    \n",
    "    df_tr.to_sql(con=sql_engine, name='fact_rfm_threshold_sbu', schema='dev_db', if_exists='append',index=False)\n",
    "    del df_rfm1\n",
    "    del rfm_base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#RFM SCHEMA 2023\n",
    "order_list = ['mfr']\n",
    "\n",
    "segment_map = { r'1[1-2]1': 'Champion',\n",
    "            \n",
    "            r'1[1-2]2': 'Promising',\n",
    "            r'1[3-4][1-2]': 'Promising',\n",
    "            \n",
    "            r'1[1-4]3': 'Loyalist',\n",
    "            r'2[1-2][1-3]': 'Loyalist',\n",
    "\n",
    "            r'1[1-4]4': 'Potential Loyalist',\n",
    "            r'2[1-2]4': 'Potential Loyalist',\n",
    "            r'2[3-4][1-4]': 'Potential Loyalist',\n",
    " \n",
    "            r'3[1-3][1-4]': 'Unsteady',\n",
    "            \n",
    "            r'34[1-4]': 'Needs Attention',\n",
    "            \n",
    "            r'4[1-3][1-4]': 'At Risk',\n",
    "            r'44[1-2]': 'At Risk',\n",
    "\n",
    "            r'44[1-4]': 'About to Lose'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure temp helper table was ready\n",
    "\n",
    "sql_engine = sql_engine_server\n",
    "sql_engine.execute(\"\"\"TRUNCATE TABLE dev_db.temp_rfm_market \"\"\")\n",
    "sql_engine.execute(\"\"\"TRUNCATE TABLE dev_db.temp_rfm_market_forgotten_users \"\"\")\n",
    "sql_engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with end period only\n",
    "# with helper\n",
    "for i in all_sbu_mapping :\n",
    "    \n",
    "    # ORI\n",
    "    # print(i)\n",
    "    sbuname_ = list(i.keys())[0]\n",
    "    print(sbuname_)\n",
    "    \n",
    "    prev_year=datetime.strptime(end_period,'%Y-%m-%d').year-1\n",
    "    \n",
    "    # for end_period in end_period_list:\n",
    "    \n",
    "    #new make helper\n",
    "    sql_engine = sql_engine_server\n",
    "    q=text(i[sbuname_]['helper_rfm'].replace('<end_period>',str(end_period)).replace('<n_year>', str(2)))\n",
    "    print(q)\n",
    "    \n",
    "    df_rfm0 = pd.read_sql(q, sql_engine)\n",
    "    df_rfm0.to_sql(con=sql_engine, name='temp_rfm_market', schema='dev_db',if_exists='append', index=False, chunksize=30000) ##\n",
    "    sql_engine.dispose()\n",
    "    del df_rfm0\n",
    "    print('rfm market created')\n",
    "    \n",
    "    \n",
    "    sql_engine = sql_engine_server\n",
    "    q=text(i[sbuname_]['rfm_query'].replace('<end_period>',str(end_period)).replace('<n_year>', str(2)))\n",
    "    print(q)\n",
    "    df_rfm1 = pd.read_sql(q, sql_engine)\n",
    "\n",
    "    \n",
    "    for v in order_list:\n",
    "    #get the data and storage it into df and upload it to server\n",
    "        sql_engine = sql_engine_server\n",
    "        df_check= pd.read_sql('select * from dev_db.fact_rfm_sbu where end_period= \"%s\" and sbu = \"%s\" limit 1' % (end_period, sbuname_), con=sql_engine)\n",
    "        if len(df_check) < 1:\n",
    "            df_tr=pd.read_sql('select threshold from dev_db.fact_rfm_threshold_sbu where sbu =\"%s\" and year(period)= %s  limit 1' % (sbuname_, prev_year), con=sql_engine)  \n",
    "            if len(df_tr)<1:\n",
    "                generate_threshold(sbuname_, i[sbuname_], prev_year, segment_map, order = v)\n",
    "                df_tr=pd.read_sql('select threshold from dev_db.fact_rfm_threshold_sbu where sbu =\"%s\" and year(period)= %s  limit 1' % (sbuname_, prev_year), con=sql_engine)\n",
    "            try:\n",
    "                threshold = json.loads(df_tr.threshold.iloc[0].replace(\"'\",'\"'))\n",
    "            except:\n",
    "                _error_concept.append(sbuname_)\n",
    "                continue\n",
    "            \n",
    "            if len(df_rfm1) > 0 :\n",
    "                #initiate rfm instance\n",
    "                rfm_static = rfm(df_rfm1.copy(),segment_map, order= v)\n",
    "                #set threshold manually using the 1-year threshold\n",
    "                rfm_static.set_threshold(threshold=threshold)\n",
    "                #execute rfm\n",
    "                df_rfm_static=rfm_static.fit() \n",
    "                df_rfm_static.reset_index(drop=True, inplace=True)\n",
    "                #save rfm to db\n",
    "                \n",
    "                # sql_engine = sql_engine_server\n",
    "                # sql_engine = sql.create_engine('mysql://'+username+':'+password+'@'+host+'/?charset=utf8mb4')\n",
    "                \n",
    "                sql_engine = sql_engine_server\n",
    "                df_rfm_static.to_sql(con=sql_engine, name='fact_rfm_sbu', schema='dev_db',if_exists='append', index=False, chunksize=30000) ##\n",
    "                sql_engine.dispose()\n",
    "                print(v+' '+ sbuname_ +' '+end_period+' inserted')\n",
    "                sql_engine.dispose()\n",
    "                \n",
    "\n",
    "                \n",
    "        #check if forgotten_user for the designated SBU and end_period already exist. if not, create the forgotten_user\n",
    "        # df_check2= pandas.read_sql('select * from gclub.forgotten_usersV2_concept where end_period= \"%s\" and concept = \"%s\" limit 1' % (end_period,i), con=sql_engine)\n",
    "        sql_engine = sql_engine_server\n",
    "        df_check2= pd.read_sql('select * from dev_db.fact_forgotten_user_sbu where end_period= \"%s\" and sbu = \"%s\" limit 1' % (end_period, sbuname_), con=sql_engine)\n",
    "        \n",
    "        if len(df_check2) < 1:\n",
    "            # ORI\n",
    "            # q=text(mapping[i]['forgotten_user_query'].replace('<end_period>',str(end_period)).replace('<count_current_rfm>',' '+str(df_rfm1.member_id.nunique())+' '))\n",
    "            #new make helper\n",
    "            sql_engine = sql_engine_server\n",
    "            q=text(i[sbuname_]['helper_forgot'].replace('<end_period>',str(end_period)).replace('<n_year>', str(2)))\n",
    "            print(q)\n",
    "            \n",
    "            df_rfm0 = pd.read_sql(q, sql_engine)\n",
    "            df_rfm0.to_sql(con=sql_engine, name='temp_rfm_market_forgotten_users', schema='dev_db',if_exists='append', index=False, chunksize=30000) ##\n",
    "            sql_engine.dispose()\n",
    "            del df_rfm0\n",
    "            print('rfm market forgotton created')\n",
    "            \n",
    "            sql_engine = sql_engine_server\n",
    "            q=text(i[sbuname_]['forgotten_user_query'].replace('<end_period>',str(end_period)).replace('<count_current_rfm>',' '+str(df_rfm1.member_id.nunique())+' '))\n",
    "            df_fu = pd.read_sql(q, con=sql_engine)\n",
    "            sql_engine.dispose()\n",
    "            \n",
    "            sql_engine = sql_engine_server\n",
    "            df_fu.to_sql(con=sql_engine, name='fact_forgotten_user_sbu', schema='dev_db',if_exists='append', index=False, chunksize=30000) ##\n",
    "            sql_engine.dispose()\n",
    "            \n",
    "            print('forggooton user done')\n",
    "\n",
    "        sql_engine = sql_engine_server\n",
    "        sql_engine.execute(\"\"\"TRUNCATE TABLE dev_db.temp_rfm_market \"\"\")\n",
    "        sql_engine.execute(\"\"\"TRUNCATE TABLE dev_db.temp_rfm_market_forgotten_users \"\"\")\n",
    "        sql_engine.dispose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv. Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_rfm1, df_rfm_static, df_fu\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
