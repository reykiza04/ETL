{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "## this notebook was part 2/2 of SBU\n",
    "\n",
    "- SUB SBU  est 4 jam\n",
    "\n",
    "- Run on :tanggal 6 jam 6 -> tanggal 5 jam 23\n",
    "\n",
    "cron config: 0 0 23 5 1/1 ? *\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "import sqlalchemy as sql\n",
    "from sqlalchemy.pool import NullPool\n",
    "import gc\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy.sql import text\n",
    "import calendar\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to DWH\n",
    "username = \"\"\n",
    "password = \"********\"\n",
    "host = \"\" \n",
    "\n",
    "\n",
    "connect_string = 'mysql://'+username+':'+quote(password)+'@'+host+'/?charset=utf8mb4'\n",
    "sql_engine_server = sql.create_engine(connect_string, poolclass=NullPool)\n",
    "sql_engine_server.connect()\n",
    "\n",
    "# configure max lenght\n",
    "query = text(\"SET GLOBAL group_concat_max_len = 10000\")\n",
    "sql_engine_server.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test Conection\n",
    "connect_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test concection\n",
    "sql.create_engine(connect_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Declare Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%python\n",
    "#get transaction period for the current update fot the threshold period\n",
    "\n",
    "def monthdelta(date, delta):\n",
    "    m, y = (date.month+delta) % 12, date.year + ((date.month)+delta-1) //12\n",
    "    if not m: m = 12\n",
    "    d = min(date.day, \n",
    "        [31, 29 if y%4==0 and (not y%100==0 or y%400 == 0) else 28,\n",
    "        31,30,31,30,31,31,30,31,30,31][m-1])\n",
    "    return date.replace(day=d,month=m,year=y)\n",
    "    \n",
    "m=monthdelta(datetime.today(), -1).month\n",
    "y=monthdelta(datetime.today(), -1).year\n",
    "d=calendar.monthrange(y, m)[1]\n",
    "prev_year = datetime(y, m, d).year-1\n",
    "end_period = str(datetime(y, m, d).date())\n",
    "\n",
    "# end_period_list= ('2022-12-31','2023-01-31','2023-02-28','2023-03-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class rfm:\n",
    "    \n",
    "    def __init__(self, df, segment_map, threshold={}, order='rfm'):\n",
    "        self.segment_map=segment_map\n",
    "        self.order=order\n",
    "        self.df = df\n",
    "        self.threshold = threshold.copy()\n",
    "        #if the threshold is not set manually, it will be automatically set using the df distribution (quantile)\n",
    "        \n",
    "        if self.threshold=={}:\n",
    "            self.threshold['recency'] = [self.df.recency_days.quantile(.25),self.df.recency_days.quantile(.5),self.df.recency_days.quantile(.75)]\n",
    "            self.threshold['frequency'] = [self.df.freq.quantile(.25),self.df.freq.quantile(.5),self.df.freq.quantile(.75)]\n",
    "            self.threshold['monetary'] = [self.df.total_value.quantile(.25),self.df.total_value.quantile(.5),self.df.total_value.quantile(.75)]\n",
    "            \n",
    "    #set the threshold manually\n",
    "    def set_threshold(self,threshold={}):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "\n",
    "    def tier_marker(self,series,metric):\n",
    "        q = self.threshold[metric]\n",
    "        return series.apply(lambda x: 4 if x <= q[0] else 3 if (x > q[0] and x <= q[1]) else 2 if (x > q[1] and x <= q[2]) else 1  )\n",
    "        \n",
    "        \n",
    "    def fit(self):\n",
    "        self.df['recency_tier'] = self. tier_marker(self.df.recency_days,'recency')\n",
    "        self.df['freq_tier'] = self.tier_marker(self.df.freq,'frequency')\n",
    "        self.df['total_value_tier'] = self.tier_marker(self.df.total_value,'monetary')\n",
    "        #self.df['avg_value_tier'] = self.tier_marker(self.df.avg_value)\n",
    "\n",
    "        if self.order=='mfr':\n",
    "            self.df['combined_tier'] = self.df.apply(lambda x :   str(x.total_value_tier)+ str(x.freq_tier) + str(x.recency_tier), axis=1 )\n",
    "        elif self.order=='fmr':\n",
    "            self.df['combined_tier'] = self.df.apply(lambda x :   str(x.freq_tier) + str(x.total_value_tier)+str(x.recency_tier), axis=1 )\n",
    "        elif self.order=='frm':\n",
    "            self.df['combined_tier'] = self.df.apply(lambda x :   str(x.freq_tier) +str(x.recency_tier) + str(x.total_value_tier), axis=1 )\n",
    "        else:\n",
    "            #rfm order\n",
    "            self.df['combined_tier'] = self.df.apply(lambda x : str(x.recency_tier) + str(x.freq_tier) + str(x.total_value_tier), axis=1 )\n",
    "        \n",
    "        self.df['segment'] = self.df['combined_tier'].replace(self.segment_map, regex=True)\n",
    "    \n",
    "        rank_map = {\n",
    "                    'Champion':1,\n",
    "                   'Promising':2,\n",
    "                   'Loyalist':3,\n",
    "                   'Potential Loyalist':4,\n",
    "                   'Unsteady':5,\n",
    "                   'Needs Attention':6,\n",
    "                    'At Risk':7,\n",
    "                    'About to Lose':8\n",
    "                   }\n",
    "        self.df['segment_rank'] = self.df['segment'].apply(lambda x: rank_map[x])\n",
    "        return self.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_threshold(sbu,m, year, segment_map, order):\n",
    "    #create 1 year rfm to generate 1-year threshold which will be applied to 2-year rfm\n",
    "    end_date=str(year)+\"-12-31\"\n",
    "    tr=[]\n",
    "    sql_engine = sql_engine_server\n",
    "    # sql_engine = sql.create_engine('mysql://mohammad:%s@147.139.173.222/?charset=utf8'% quote('P@ssw0rd2019!'))\n",
    "    \n",
    "    q=text(m['rfm_query'].replace('<end_period>',str(end_date)).replace('<n_year>',str(1)))\n",
    "    print(q)\n",
    "    df_rfm1 = pd.read_sql(q, sql_engine)\n",
    "    \n",
    "    rfm_base_model = rfm(df_rfm1.copy(),segment_map, order=order)\n",
    "    print(rfm_base_model.threshold)\n",
    "    \n",
    "    \n",
    "    df_tr = pd.DataFrame()\n",
    "    df_tr['threshold'] = [rfm_base_model.threshold,]\n",
    "    df_tr['SBU']= sbu\n",
    "    df_tr['mapping']= q\n",
    "    df_tr['period'] = end_date\n",
    "    \n",
    "    df_tr.to_sql(con=sql_engine, name='fact_rfm_threshold_sbu', schema='dev_db', if_exists='append',index=False)\n",
    "    del df_rfm1\n",
    "    del rfm_base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#RFM SCHEMA 2023\n",
    "order_list = ['mfr']\n",
    "\n",
    "segment_map = { r'1[1-2]1': 'Champion',\n",
    "            \n",
    "            r'1[1-2]2': 'Promising',\n",
    "            r'1[3-4][1-2]': 'Promising',\n",
    "            \n",
    "            r'1[1-4]3': 'Loyalist',\n",
    "            r'2[1-2][1-3]': 'Loyalist',\n",
    "\n",
    "            r'1[1-4]4': 'Potential Loyalist',\n",
    "            r'2[1-2]4': 'Potential Loyalist',\n",
    "            r'2[3-4][1-4]': 'Potential Loyalist',\n",
    " \n",
    "            r'3[1-3][1-4]': 'Unsteady',\n",
    "            \n",
    "            r'34[1-4]': 'Needs Attention',\n",
    "            \n",
    "            r'4[1-3][1-4]': 'At Risk',\n",
    "            r'44[1-2]': 'At Risk',\n",
    "\n",
    "            r'44[1-4]': 'About to Lose'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Mapping Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q2=\"\"\"SELECT  SUB_SBU SBU,GROUP_CONCAT(CONCAT('\"',`Concept Name`,'\"') SEPARATOR ',') ConceptName\n",
    "FROM (select distinct SUB_SBU,`Concept Name`  from gclub.rfm_helper\n",
    "where SUB_SBU in('MAA Fashion Footwear','MAA Sports','MAA Kids')order by SUB_SBU ) a\n",
    "GROUP BY a.SUB_SBU\"\"\"\n",
    "\n",
    "\n",
    "final_df1 = pd.read_sql_query(q2, sql_engine_server)\n",
    "final_df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df1['ConceptName'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df  = final_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ver forgot less\n",
    "all_sbu_mapping = []\n",
    "\n",
    "for concept_list_tableau, concept_list_master in zip(final_df['SBU'], final_df['ConceptName']):\n",
    "    all_sbu_mapping.append(\n",
    "    {\n",
    "\n",
    "    f'{concept_list_tableau}': \n",
    "    {\n",
    "        \n",
    "    'helper_rfm':\n",
    "    f\"\"\" \n",
    "    SELECT\n",
    "    \trule.TransactionID,\n",
    "    \trule.MemberID,\n",
    "    \trule.AtLocationTime,\n",
    "    \tresults.RetailValueAfterTax VALUE,\n",
    "    \tstore.ConceptName\n",
    "    FROM\n",
    "    \tmardiyan.LoyaltyRuleServiceTransactions PARTITION(P2023,P2022,P2021) rule\n",
    "    INNER JOIN mardiyan.LoyaltyRuleServiceTransactionResults PARTITION(P2023,P2022,P2021) results\n",
    "            on\n",
    "    \trule.TransactionID = results.TransactionID\n",
    "    LEFT join\n",
    "        mardiyan.MasterStoresV2 store\n",
    "        ON\n",
    "    \trule.LocationReference = store.StoreCode\n",
    "    \tAND rule.AtLocationTime BETWEEN store.ValidFrom AND store.ValidUntil\n",
    "    WHERE\n",
    "    \tstore.conceptname IN ({concept_list_master})\n",
    "    \tAND rule.AtLocationTime > Date_sub('<end_period>', INTERVAL 2 year)\n",
    "    \tAND rule.AtLocationTime <= '<end_period>'\n",
    "    \tAND rule.Status = 'COMPLETED'\n",
    "    \"\"\",\n",
    "\n",
    "        \n",
    "    'rfm_query':\n",
    "    f\"\"\"SELECT\n",
    "    b.MemberID AS member_id,\n",
    "    \"{concept_list_tableau}\" AS SBU,\n",
    "    'dynamic' AS threshold ,\n",
    "    Date_sub('<end_period>', INTERVAL 2 YEAR) AS start_period,\n",
    "    '<end_period>' AS end_period,\n",
    "    COUNT(DISTINCT(b.TransactionID)) freq,\n",
    "    SUM(b.VALUE) total_value,\n",
    "    AVG(b.VALUE) avg_value,\n",
    "    max(DATEDIFF(b.AtLocationTime, '<end_period>')) recency_days\n",
    "    FROM\n",
    "    dev_db.temp_rfm_market b\n",
    "    GROUP BY\n",
    "    b.MemberID\n",
    "    \"\"\",\n",
    "    \n",
    "    \n",
    "    \n",
    "    'helper_forgot':\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "    \tDISTINCT a.ssoid\n",
    "    FROM\n",
    "    \tgclub.MemberIDgroupBySales_2016_2018 a\n",
    "    WHERE\n",
    "    \ta.conceptname IN ({concept_list_master})\n",
    "    UNION ALL\n",
    "            select\n",
    "    \tDISTINCT rule.memberid ssoid\n",
    "    FROM\n",
    "    \tmardiyan.LoyaltyRuleServiceTransactions PARTITION(P2023,P2022,P2021,P2020,P2019) rule\n",
    "    LEFT JOIN mardiyan.MasterStoresV2 store ON\n",
    "    \trule.LocationReference = store.StoreCode\n",
    "    \tAND rule.AtLocationTime BETWEEN store.ValidFrom AND store.ValidUntil\n",
    "    WHERE\n",
    "    \tstore.conceptname IN ({concept_list_master})\n",
    "    \tAND rule.atlocationtime >= '2019-01-01'\n",
    "    \tAND rule.atlocationtime <= '<end_period>'\n",
    "    \tAND rule.Status = 'COMPLETED'\n",
    "    \n",
    "    \"\"\" ,\n",
    "    \n",
    "    'forgotten_user_query': \n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "\t\"{concept_list_tableau}\" SBU,\n",
    "\tDate_sub('<end_period>', INTERVAL 2 YEAR) start_period,\n",
    "\t'<end_period>' end_period,\n",
    "\t(\n",
    "\tSELECT\n",
    "\t\tCOUNT(DISTINCT dev_db.temp_rfm_market_forgotten_users.ssoid)\n",
    "\tFROM\n",
    "\t\tdev_db.temp_rfm_market_forgotten_users ) - <count_current_rfm> forgotten_users\n",
    "     \"\"\"\n",
    "    \n",
    "}\n",
    "}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(all_sbu_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_error_concept = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_engine = sql_engine_server\n",
    "sql_engine.execute(\"\"\"TRUNCATE TABLE dev_db.temp_rfm_market \"\"\")\n",
    "sql_engine.execute(\"\"\"TRUNCATE TABLE dev_db.temp_rfm_market_forgotten_users \"\"\")\n",
    "sql_engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with end period list\n",
    "#with helper\n",
    "for i in all_sbu_mapping :\n",
    "    \n",
    "    # ORI\n",
    "    # print(i)\n",
    "    sbuname_ = list(i.keys())[0]\n",
    "    print(sbuname_)\n",
    "    \n",
    "    prev_year=datetime.strptime(end_period,'%Y-%m-%d').year-1\n",
    "    \n",
    "    # for end_period in end_period_list:\n",
    "        \n",
    "    #new make helper\n",
    "    q=text(i[sbuname_]['helper_rfm'].replace('<end_period>',str(end_period)).replace('<n_year>', str(2)))\n",
    "    print(q)\n",
    "    sql_engine = sql_engine_server\n",
    "    \n",
    "    df_rfm0 = pd.read_sql(q, sql_engine)\n",
    "    df_rfm0.to_sql(con=sql_engine, name='temp_rfm_market', schema='dev_db',if_exists='append', index=False, chunksize=30000) ##\n",
    "    sql_engine.dispose()\n",
    "    del df_rfm0\n",
    "    print('rfm market created')\n",
    "    \n",
    "    sql_engine = sql_engine_server\n",
    "    q=text(i[sbuname_]['rfm_query'].replace('<end_period>',str(end_period)).replace('<n_year>', str(2)))\n",
    "    print(q)\n",
    "    df_rfm1 = pd.read_sql(q, sql_engine)\n",
    "    # sql_engine.dispose()\n",
    "\n",
    "    \n",
    "    for v in order_list:\n",
    "        sql_engine = sql_engine_server\n",
    "\n",
    "    #get the data and storage it into df and upload it to server\n",
    "\n",
    "\n",
    "\n",
    "        df_check= pd.read_sql('select * from dev_db.fact_rfm_sbu where end_period= \"%s\" and sbu = \"%s\" limit 1' % (end_period, sbuname_), con=sql_engine)\n",
    "        if len(df_check) < 1:\n",
    "            df_tr=pd.read_sql('select threshold from dev_db.fact_rfm_threshold_sbu where sbu =\"%s\" and year(period)= %s  limit 1' % (sbuname_, prev_year), con=sql_engine)  \n",
    "            if len(df_tr)<1:\n",
    "                generate_threshold(sbuname_, i[sbuname_], prev_year, segment_map, order = v)\n",
    "                df_tr=pd.read_sql('select threshold from dev_db.fact_rfm_threshold_sbu where sbu =\"%s\" and year(period)= %s  limit 1' % (sbuname_, prev_year), con=sql_engine)\n",
    "            try:\n",
    "                threshold = json.loads(df_tr.threshold.iloc[0].replace(\"'\",'\"'))\n",
    "            except:\n",
    "                _error_concept.append(sbuname_)\n",
    "                continue\n",
    "            \n",
    "            if len(df_rfm1) > 0 :\n",
    "                #initiate rfm instance\n",
    "                rfm_static = rfm(df_rfm1.copy(),segment_map, order= v)\n",
    "                #set threshold manually using the 1-year threshold\n",
    "                rfm_static.set_threshold(threshold=threshold)\n",
    "                #execute rfm\n",
    "                df_rfm_static=rfm_static.fit() \n",
    "                df_rfm_static.reset_index(drop=True, inplace=True)\n",
    "                #save rfm to db\n",
    "                \n",
    "                sql_engine = sql_engine_server\n",
    "                # sql_engine = sql.create_engine('mysql://'+username+':'+password+'@'+host+'/?charset=utf8mb4')\n",
    "                df_rfm_static.to_sql(con=sql_engine, name='fact_rfm_sbu', schema='dev_db',if_exists='append', index=False, chunksize=30000) ##\n",
    "                sql_engine.dispose()\n",
    "                print(v+' '+ sbuname_ +' '+end_period+' inserted')\n",
    "                sql_engine.dispose()\n",
    "                \n",
    "\n",
    "                \n",
    "        #check if forgotten_user for the designated SBU and end_period already exist. if not, create the forgotten_user\n",
    "        # df_check2= pandas.read_sql('select * from gclub.forgotten_usersV2_concept where end_period= \"%s\" and concept = \"%s\" limit 1' % (end_period,i), con=sql_engine)\n",
    "        sql_engine = sql_engine_server\n",
    "        df_check2= pd.read_sql('select * from dev_db.fact_forgotten_user_sbu where end_period= \"%s\" and sbu = \"%s\" limit 1' % (end_period, sbuname_), con=sql_engine)\n",
    "        \n",
    "        if len(df_check2) < 1:\n",
    "            # ORI\n",
    "            # q=text(mapping[i]['forgotten_user_query'].replace('<end_period>',str(end_period)).replace('<count_current_rfm>',' '+str(df_rfm1.member_id.nunique())+' '))\n",
    "            #new make helper\n",
    "            sql_engine = sql_engine_server\n",
    "            q=text(i[sbuname_]['helper_forgot'].replace('<end_period>',str(end_period)).replace('<n_year>', str(2)))\n",
    "            print(q)\n",
    "            \n",
    "            df_rfm0 = pd.read_sql(q, sql_engine)\n",
    "            df_rfm0.to_sql(con=sql_engine, name='temp_rfm_market_forgotten_users', schema='dev_db',if_exists='append', index=False, chunksize=30000) ##\n",
    "            sql_engine.dispose()\n",
    "            del df_rfm0\n",
    "            print('rfm market forgotton created')\n",
    "            \n",
    "            sql_engine = sql_engine_server\n",
    "            q=text(i[sbuname_]['forgotten_user_query'].replace('<end_period>',str(end_period)).replace('<count_current_rfm>',' '+str(df_rfm1.member_id.nunique())+' '))\n",
    "            df_fu = pd.read_sql(q, con=sql_engine)\n",
    "            df_fu.to_sql(con=sql_engine, name='fact_forgotten_user_sbu', schema='dev_db',if_exists='append', index=False, chunksize=30000) ##\n",
    "            sql_engine.dispose()\n",
    "            \n",
    "            print('forggooton user done')\n",
    "\n",
    "        sql_engine = sql_engine_server\n",
    "        sql_engine.execute(\"\"\"TRUNCATE TABLE dev_db.temp_rfm_market \"\"\")\n",
    "        sql_engine.execute(\"\"\"TRUNCATE TABLE dev_db.temp_rfm_market_forgotten_users \"\"\")\n",
    "        sql_engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null rfm threshold\n",
    "for null in sorted(list(set(_error_concept))):\n",
    "    print(null)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v.Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del df_rfm1, df_rfm_static, df_fu\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
